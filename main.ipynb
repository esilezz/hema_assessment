{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, IntegerType, DateType, FloatType\n",
    "from pyspark.sql.functions import col, input_file_name, current_date, date_format, current_timestamp, to_date, split, date_sub, count, when\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"hema-transform\")\n",
    "logger.setLevel(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(df):\n",
    "    return df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"hema-spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIRECTORY = \"./data\"\n",
    "FILENAME = \"train.csv\"\n",
    "\n",
    "# read file\n",
    "ingested_df = spark.read.format(\"csv\").option(\"header\",True).load(f\"{FILE_DIRECTORY}/{FILENAME}\")\n",
    "\n",
    "# raw file will be saved like this in the raw/landing zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'rowId': IntegerType(),\n",
    "    'orderId': StringType(),\n",
    "    'shipMode': StringType(),\n",
    "    'customerId': StringType(),\n",
    "    'customerName': StringType(),\n",
    "    'segment': StringType(),\n",
    "    'country': StringType(),\n",
    "    'city': StringType(),\n",
    "    'state': StringType(),\n",
    "    'postalCode': IntegerType(),\n",
    "    'region': StringType(),\n",
    "    'productId': StringType(), \n",
    "    'category': StringType(),\n",
    "    'subCategory': StringType(),\n",
    "    'productName': StringType(),\n",
    "    'sales': FloatType()\n",
    "}\n",
    "\n",
    "augmented_cols = ['filename', \"ingestionDate\", 'time']\n",
    "date_columns = ['orderDate', 'shipDate']\n",
    "\n",
    "# define functions and other variables \n",
    "def camel_case(s):\n",
    "    s = sub(r\"(_|-)+\", \" \", s).title().replace(\" \", \"\")\n",
    "    return ''.join([s[0].lower(), s[1:]])\n",
    "\n",
    "def augment_dataframe(df: DataFrame, filename: str):\n",
    "    if augmented_cols in df.columns:\n",
    "        df = df.drop(('filename', \"ingestionDate\", 'time'))\n",
    "    \n",
    "    df = (\n",
    "        df\n",
    "        .withColumn('filename', filename)\n",
    "        .withColumn(\"ingestionDate\", current_date())\n",
    "        .withColumn(\"curr_timestamp\", current_timestamp())\n",
    "        .withColumn('time', date_format('curr_timestamp', 'HH:mm:ss'))\n",
    "        .drop(col(\"curr_timestamp\"))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def ingestion_to_raw(df: DataFrame, filename: str):\n",
    "    logger.info(\"Processing from original to raw format...\")\n",
    "    raw_df = augment_dataframe(df, filename)\n",
    "    logger.info(\"Done!\")\n",
    "    return raw_df\n",
    "\n",
    "def raw_to_curated_pipeline(df: DataFrame, filename: str):\n",
    "    logger.info(\"Processing from raw to curated format...\")\n",
    "    camelcase_column_mapping = {col: camel_case(col) for col in df.columns}\n",
    "\n",
    "    # rename columns and fix types\n",
    "    for col_name in camelcase_column_mapping:\n",
    "        if col_name in augmented_cols:\n",
    "            continue\n",
    "\n",
    "        new_name = camelcase_column_mapping[col_name]\n",
    "        if new_name in date_columns:\n",
    "            df = df.withColumnRenamed(col_name, new_name)\n",
    "            df = df.withColumn(new_name, to_date(col(new_name), \"dd/MM/yyyy\"))\n",
    "        else:\n",
    "            dtype = dtypes[new_name]\n",
    "            df = df.withColumnRenamed(col_name, new_name)\n",
    "            df = df.withColumn(new_name, col(new_name).cast(dtype))\n",
    "  \n",
    "    # add metadata to dataframe\n",
    "    curated_df = augment_dataframe(df, filename)\n",
    "    logger.info(\"Done!\")\n",
    "    return curated_df\n",
    "\n",
    "\n",
    "def curated_to_sales(df: DataFrame, filename: str):\n",
    "    sales = df.select(\n",
    "        col('orderId'), \n",
    "        col('orderDate'), \n",
    "        col('shipDate'), \n",
    "        col('shipMode'), \n",
    "        col('city')\n",
    "    )\n",
    "    sales = augment_dataframe(sales)\n",
    "    return sales\n",
    "\n",
    "def curated_to_customers(df: DataFrame, filename: str):\n",
    "    customers_info = (\n",
    "        df\n",
    "        .select(\n",
    "            col('customerId'),\n",
    "            col('customerName'),\n",
    "            col('country'),\n",
    "            col('city'),\n",
    "            col('segment')\n",
    "        )\n",
    "        .withColumn(\"customerFirstName\", split(col(\"customerName\"), \" \").getItem(0))\n",
    "        .withColumn(\"customerLastName\", split(col(\"customerName\"), \" \").getItem(1))\n",
    "        .withColumnRenamed(\"segment\", \"customerSegment\")\n",
    "    )\n",
    "\n",
    "    # calculate the cutoff dates for 5, 15, and 30 days ago\n",
    "    cutoff_5d = datetime.now() - timedelta(days=5)\n",
    "    cutoff_15d = datetime.now() - timedelta(days=15)\n",
    "    cutoff_30d = datetime.now() - timedelta(days=30)\n",
    "\n",
    "    # group the DataFrame by `customerName` and calculate the total \n",
    "    # quantity of orders in the last 5, 15 and 30 days, and the total\n",
    "    customers_orders = df.groupBy(\"customerName\").agg(\n",
    "        count(when(col(\"orderDate\") >= cutoff_5d, 1)).alias(\"quantityOfOrdersLast5Days\"),\n",
    "        count(when(col(\"orderDate\") >= cutoff_15d, 1)).alias(\"quantityOfOrdersLast15Days\"),\n",
    "        count(when(col(\"orderDate\") >= cutoff_30d, 1)).alias(\"quantityOfOrdersLast30Days\"),\n",
    "        count(col('orderDate')).alias(\"TotalQuantityOfOrder\")\n",
    "    )\n",
    "\n",
    "    customers = customers_info.join(\n",
    "        customers_orders, customers_info.customerName == customers_orders.customerName\n",
    "    )\n",
    "\n",
    "    customers = augment_dataframe(customers, filename)\n",
    "    return customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = ingestion_to_raw(ingested_df)\n",
    "curated = raw_to_curated_pipeline(raw)\n",
    "sales = curated_to_sales(curated)\n",
    "customers = curated_to_customers(curated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales dataset might contains the attributes below\n",
    "- orderId\n",
    "- orderDate (YYYY/MM/DD format) \n",
    "- shipDate (YYYY/MM/DD format) \n",
    "- shipMode\n",
    "- city\n",
    "\n",
    "Customer dataset might contains the attributes below, considering that quantity of orders should be calculated filed based on raw data:\n",
    "- customerId \n",
    "- customerName \n",
    "- customerFirstName \n",
    "- customeLastName \n",
    "- customerSegment \n",
    "- country\n",
    "- city \n",
    "- quantityOfOrders(last5Days) \n",
    "- quantityOfOrders(last15Days) \n",
    "- quantityOfOrders(last30Days) \n",
    "- totalQuantityOfOrders\n",
    "\n",
    "Customer dataset should be rewritten every run of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = curated.select(\n",
    "    col('orderId'), \n",
    "    col('orderDate'), \n",
    "    col('shipDate'), \n",
    "    col('shipMode'), \n",
    "    col('city')\n",
    ")\n",
    "visualize(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_info = (\n",
    "    curated\n",
    "    .select(\n",
    "        col('customerId'),\n",
    "        col('customerName'),\n",
    "        col('country'),\n",
    "        col('city'),\n",
    "        col('segment')\n",
    "    )\n",
    "    .withColumn(\"customerFirstName\", split(col(\"customerName\"), \" \").getItem(0))\n",
    "    .withColumn(\"customerLastName\", split(col(\"customerName\"), \" \").getItem(1))\n",
    "    .withColumnRenamed(\"segment\", \"customerSegment\")\n",
    ")\n",
    "\n",
    "# calculate the cutoff dates for 5, 15, and 30 days ago\n",
    "cutoff_5d = datetime.now() - timedelta(days=5)\n",
    "cutoff_15d = datetime.now() - timedelta(days=15)\n",
    "cutoff_30d = datetime.now() - timedelta(days=30)\n",
    "\n",
    "# group the DataFrame by `customerName` and calculate the total \n",
    "# quantity of orders in the last 5, 15 and 30 days, and the total\n",
    "customers_orders = curated.groupBy(\"customerName\").agg(\n",
    "    count(when(col(\"orderDate\") >= cutoff_5d, 1)).alias(\"quantityOfOrdersLast5Days\"),\n",
    "    count(when(col(\"orderDate\") >= cutoff_15d, 1)).alias(\"quantityOfOrdersLast15Days\"),\n",
    "    count(when(col(\"orderDate\") >= cutoff_30d, 1)).alias(\"quantityOfOrdersLast30Days\"),\n",
    "    count(col('orderDate')).alias(\"TotalQuantityOfOrder\")\n",
    ")\n",
    "\n",
    "customers = customers_info.join(customers_orders, customers_info.customerName == customers_orders.customerName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('hema')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b028067cc866461c1218227bc70709ea477b6dd02dd167f0b6cdf6b12926b0ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
